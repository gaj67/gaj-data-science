{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3bf0687",
   "metadata": {},
   "source": [
    "# AFL Match Outcome Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e37e17",
   "metadata": {},
   "source": [
    "The purpose of the current set of notebooks is to explore the historical data and modelling relevant to predicting the outcomes of given AFL matches. In particular, if we know an upcoming match is between team A and team B, then we wish to estimate the probabilities that team A wins (and team B loses), team B wins (and team A loses), or the match is a draw."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb7ba60",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5745f195",
   "metadata": {},
   "source": [
    "### Australian Rules Football"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ec0f2",
   "metadata": {},
   "source": [
    "Australian Rules Football is a game played between two opposing teams, say team A and team B. Each match takes place over four quarters, with each quarter having approximately 30 minutes duration. During each quarter, team A attempts to kick or hand-pass the football towards their scoring end of the oval, and team B attempts to send the ball to the opposite end of the oval. The scoring ends swap after each quarter.\n",
    "\n",
    "The scoring area consists of four (almost) equally spaced posts, forming the \"goal\" area between the inner two posts (the goal posts) and two \"behind\" areas between the outer two posts (the behind posts) and the inner two posts. If the football is kicked between the goal posts (without touching either post), then the scoring team scores a goal worth 6 points.\n",
    "If the ball is kicked between a behind post and a goal post (without touching), then the scoring team scores a behind worth 1 point. If the ball touches or hits a goal post, then this scores as a behind. If the ball touches or hits a behind post, then this results in an \"out-of-bounds\" free (penalty kick-out) for the opposing team, with no change in score. If the ball is touched by hand (by either team) before going in for a goal, then this is also regarded as a behind. There are further rules regarding whether team B 'scoring' in team A's area results in a behind or a free for team A.\n",
    "\n",
    "At the end of the fourth quarter, i.e. at the end of the match, if team A and team B have the same point scores, then the match is a draw (worth 2 match points to each team). Otherwise, the team with the most points wins (gaining 4 match points), and the opposing team loses (gaining 0 match points). We shall sometimes refer to a non-drawn game as having an *outright* or *definite* result.\n",
    "\n",
    "Each week during the football season, known as a \"round\", pairs of teams (within the same league, obviously) play matches. At the end of each round, all teams are ranked on the league ladder by match points. Ties are broken based on the accumulated number of points scored for (i.e. by) and against each team. At the end of the so-called \"minor\" rounds, the teams in the top-half of the ladder go into the \"finals\" rounds. Ultimately, only two teams oppose each other in the grand final match of the season, with the winning team becoming the season champions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad75a90b",
   "metadata": {},
   "source": [
    "### AFL Teams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b458c7f6",
   "metadata": {},
   "source": [
    "The Australian Football League (AFL) was oficially formed in 1990, largely as a nationalised rebranding of the Victorian Footbal League (VFL).\n",
    "\n",
    "Between the seasons of 1996 and 1997, there were many changes including the formation of new teams, the merger of existing teams, and the renaming of existing teams. Hence, for convenience, we shall typically consider AFL data from 1997 onwards. In particular, we shall focus on the current 18 teams, listed below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0ebc16",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr><th>Team name</th><th>Comments</th></tr>\n",
    "    <tr><td>Adelaide Crows</td><td>Formed in 1991</td></tr>\n",
    "    <tr><td>Brisbane Lions</td><td>Formed in 1997 by merger of Brisbane Bears with Fitzroy</td></tr>\n",
    "    <tr><td>Carlton Blues</td></tr>\n",
    "    <tr><td>Collingwood Magpies</td></tr>\n",
    "    <tr><td>Essendon Bombers</td></tr>\n",
    "    <tr><td>Fremantle Dockers</td><td>Formed in 1995</td></tr>\n",
    "    <tr><td>Geelong Cats</td></tr>\n",
    "    <tr><td>Gold Coast Suns</td><td>Formed in 2011</td></tr>\n",
    "    <tr><td>Greater Western Sydney (GWS) Giants</td><td>Formed in 2012</td></tr>\n",
    "    <tr><td>Hawthorn Hawks</td></tr>\n",
    "    <tr><td>Melbourne Demons</td></tr>\n",
    "    <tr><td>North Melbourne Kangaroos</td><td>Named Kangaroos from 1999-2007</td></tr>\n",
    "    <tr><td>Port (Adelaide) Power</td><td>Formed in 1997</td></tr>\n",
    "    <tr><td>Richmond Tigers</td></tr>\n",
    "    <tr><td>St Kilda Saints</td></tr>\n",
    "    <tr><td>Sydney Swans</td><td>Formed in 1982 from South Melbourne</td></tr>\n",
    "    <tr><td>West Coast Eagles</td><td>Formed in 1987</td></tr>\n",
    "    <tr><td>Western Bulldogs</td><td>Renamed in 1997 from Footscray</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ee492e",
   "metadata": {},
   "source": [
    "## Match Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25709314",
   "metadata": {},
   "source": [
    "The data files used in this project were formed by saving the entire match data (over all seasons) separately for each team, found as web pages on [AFL Tables](https://afltables.com/afl/afl_index.html \"afltables.com\").\n",
    "\n",
    "Note that these data files contain both AFL matches and VFL matches (prior to the official formation of the AFL in 1990). We ignore the VFL data.\n",
    "\n",
    "Also note that the AFL data contain more team names than our list of the current 18 teams (above). In particular, the data file for North Melbourne contains matches for the team listed both under North Melbourne and under Kangaroos. For simplicity, teams that have been renamed over time (i.e. Kangaroos and Footscray) will be mapped to their current names.\n",
    "\n",
    "However, teams that resulted from the merger of previous teams remain\n",
    "problematic. For example, the Brisbane Lions first appeared in 1997,\n",
    "formed from the merger of Fitzroy and the Brisbane Bears. We cannot simply rename Fitzroy and the Brisbane Bears as the Brisbane Lions, \n",
    "because then prior to 1997 the Brisbane Lions would appear in two different places in the league rankings, and would apparently play matches against themselves. To avoid this awkwardness, we simply ignore matches prior to 1997 for convenience.\n",
    "\n",
    "The remaining difficulty is that, despite our devices above, the number of teams competing in any given season varies year by year.\n",
    "For instance, the Gold Coast Suns were formed in 2011, and the Greater Western Sydney Giants were formed in 2012. Hence, the \n",
    "current 18 teams only appear together from 2012 onwards.\n",
    "We cannot avoid this issue using pre-2012 data, and must make allowances for the league\n",
    "teams in each season, where this affects our analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfde8c3",
   "metadata": {},
   "source": [
    "## Issues and Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcccb403",
   "metadata": {},
   "source": [
    "We briefly discuss various issues that will affect our analyses, in particular our assignments of  probabilities to the various match outcomes (i.e. a win, draw, or loss)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135c9b3d",
   "metadata": {},
   "source": [
    "### The effect of draws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f6ae42",
   "metadata": {},
   "source": [
    "Unlike many other sporting games, Australian Rules Football may validly result in a draw between the two teams competing in any given match. However, since draws historically account for fewer than 1% of match outcomes, they are clearly very difficult to predict. \n",
    "\n",
    "In fact, a draw is somewhat anomalous in that it could have been avoided if the circumstances of an actual drawn match had been slightly different. One can imagine, for example, a situation in which a ball that bounced awkwardly into the goal had instead bounced the other way (resulting in no score), or if a ball that hit the goal post (thereby scoring only a behind) had instead sailed between the posts (scoring a goal). Alternative realities aside, a draw, i.e. a zero difference between the scores of the two teams at the end of a match, is essentially an unstable equilibrium.\n",
    "\n",
    "Thus, although we need to account for draws, how do we deal with them in the data? One approach is to regard a draw as both a win and a loss for each team. Indeed, although an outright result gives the winning team 4 match points (with 0 match points given to the losing team), for a draw both teams gain 2 match points (i.e. half each). Hence, we could\n",
    "regard a draw between team A and team B as both a win for team A and a win for team B, but weighted at 0.5 each (so that the total number of matches is not altered in the data). This approach has some theoretical\n",
    "support (see [Appendix C](C_regression_models.ipynb#Bernoulli-distribution \n",
    "\"Section: Bernoulli distribution\")).\n",
    "\n",
    "Another approach is to simply discard draws, which will have little effect since they only account for 1% of the data. However, we do not recommend discarding data within any given season (although we will leave aside entire seasons if necessary). For instance, removing draws from the dataset would make it impossible to correctly compute the number of match points for each team in the league ranking. Additionally, neglecting draws would lose relevant information, namely that a draw between teams A and B indicates that those teams were\n",
    "of roughly equal strength (at least for that match).\n",
    "\n",
    "Consequently, we preserve drawn matches in the historical data, but accept being unable to accurately predict them. In fact, in some modelling approaches it is more convenient to simply ignore draws as a possible outcome, and just predict the probability of a win for team A against team B. If necessary, we could then back-adjust such binary models to allow for a fixed probability of a draw."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16039c0",
   "metadata": {},
   "source": [
    "### Causality and independence of observations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b5516",
   "metadata": {},
   "source": [
    "It is apparent that the outcome of a past match in year $X$ might affect the predicted outcome of a future match in year $Y\\ge X$. It is less apparent, but still true, that the outcome of the future match might affect the *prediction* of the outcome a past match once it becomes known. However, causality prevents the future match from actually affecting the outcome of the past match. Thus, *outcomes* have a time-directionality and obey causality, but *predictions* do not have to do so. \n",
    "\n",
    "To put this more clearly, suppose we predict the probability that team A wins a match at some time $T=t$. Subsequently, we might observe the outcome of a later match at time $T>t$, and use this knowledge to re-predict a different value for the probability of team A winning the match at time $T=t$.\n",
    "This new knowledge obviously cannot change the actual outcome of that match.\n",
    "\n",
    "Given that predictions need not obey causality, we are free to predict the outcome of a match at time $T=t$ using all of the observations we have available at times $T<t$ and $T>t$.\n",
    "This is what we might typically call *retrospective* prediction,\n",
    "i.e. prediction after observing all of the data.\n",
    "However, to really be useful in practice, we desire\n",
    "*prospective* modelling, where we restrict ourselves to predictions at time $T=t$ using only past observations for times $T<t$.\n",
    "\n",
    "Thus, we might usefully adopt the Markov assumption that future matches (for $T>t$) are conditionally independent of\n",
    "past matches ($T<t$) given the present ($T=t$). In practice, this means that to predict the outcome of a match at time $T=t$, we first summarise all of the available information for $T<t$, and use just this summary information.\n",
    "\n",
    "Just to be precise, if we are, for example, counting events over time, then clearly these counts are *not* independent, since if we let\n",
    "$c^{(t)}$ represent the outcome of a match at time $t$, and $\\mathbf{x}^{(t)}$ represent the historical [features](#Feature-Extraction \"Section: Feature Extraction\") prior to the match, then\n",
    "$\\mathbf{x}^{(t)}=\\mathbf{h}(\\mathbf{x}^{(t-1)},c^{(t-1)})$ for some deterministic function \n",
    "$\\mathbf{h}$. \n",
    "However, if we **only** predict the outcome of a future match, e.g. $c^{(t)}$, based on the current features, \n",
    "e.g. $\\mathbf{x}^{(t)}$, then this prediction **is** independent of all past counts, since the current count already encapsulates the past counts.\n",
    "In other words, we have\n",
    "\\begin{eqnarray}\n",
    "P\\left(c^{(t)}\\mid\\mathbf{x}^{(t)},c^{(t-1)},\\mathbf{x}^{(t-1)}\\right)\n",
    "& = &\n",
    "P\\left(c^{(t)}\\mid c^{(t-1)},\\mathbf{x}^{(t-1)}\\right)\n",
    "~\\doteq~\n",
    "P\\left(c^{(t)}\\mid\\mathbf{x}^{(t)}\\right)\\,,\n",
    "\\end{eqnarray}\n",
    "since our model (by definition) depends only on the\n",
    "current features $\\mathbf{x}^{(t)}=\\mathbf{h}(\\mathbf{x}^{(t-1)},c^{(t-1)})$.\n",
    "\n",
    "Hence, we see that (prediction of) the future is conditionally independent of the past\n",
    "given the present, which satisfies the Markov assumption. Thus, \n",
    "letting $\\mathbf{C}=[c^{(1)},c^{(2)},\\ldots]$ be the vector of match outcomes, and\n",
    "letting $\\mathbf{X}=[\\mathbf{x}^{(1)},\\mathbf{x}^{(2)},\\ldots]$ be the matrix of match features,\n",
    "we take the pairs $(c^{(t)},\\mathbf{x}^{(t)})$ and $(c^{(t-1)},\\mathbf{x}^{(t-1)})$ to be independent in the sense that\n",
    "\\begin{eqnarray}\n",
    "P\\left(\\mathbf{C}\\mid\\mathbf{x}^{(1)}\\right) & = &\n",
    "P\\left(c^{(1)}\\mid\\mathbf{x}^{(1)}\\right)\n",
    "\\,P\\left(c^{(2)}\\mid c^{(1)},\\mathbf{x}^{(1)}\\right)\n",
    "\\,P\\left(c^{(3)}\\mid c^{(2)},c^{(1)},\\mathbf{x}^{(1)}\\right)\n",
    "\\cdots\n",
    "\\\\& \\doteq &\n",
    "P\\left(c^{(1)}\\mid\\mathbf{x}^{(1)}\\right)\\,\n",
    "P\\left(c^{(2)}\\mid\\mathbf{x}^{(2)}\\right)\\,\n",
    "P\\left(c^{(3)}\\mid\\mathbf{x}^{(3)}\\right)\\cdots\n",
    "\\\\& \\doteq &\n",
    "P(\\mathbf{C}\\mid\\mathbf{X})\\,.\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ef0c42",
   "metadata": {},
   "source": [
    "### Temporal heterogeneity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe84926",
   "metadata": {},
   "source": [
    "How much credence should we give to data observed in the past, compared to data observed in (or close to) the present? Should every season be treated equally, or should we discount (i.e. down-weight) or even neglect seasons long in the past?\n",
    "\n",
    "We know, in particular, that the players listed to play in each team vary from season to season, e.g. due to older players retiring, or under-performing players being dropped and younger (but possibly more inexperienced) players being drafted in their place. Even on a match-by-match basis within a given season, some team players will be selected to play, and others will not (due to injury, inexperience, availability, etc.). Thus, should team A in season $X$ be treated as being the same team A in season $Y$? If not, could we even model the differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e58bc9",
   "metadata": {},
   "source": [
    "Empirically, it turns out that treating all past seasons equally seems to lead to a degredation in the accuracy of predicting the current season, compared to, say, using just the results of the previous season. As discussed above, we might expect that the player list of last year's team (say, for some team A) is similar to the current year's list. However, the player list in the year before that will be less similar, and the dissimilarity will increase the further one looks into the past.\n",
    "Consequently, it should not be suprising that the match results for past seasons might be misleading for the current season. \n",
    "\n",
    "However, there is a counter-argument that must be considered. If we assume that there exists some time-independent, underlying ability of a team, then there might be a reversion-to-the-mean effect that is revealed by averaging over all past seasons. In other words, a team might have good seasons and bad seasons, but on average will have an 'average' season.\n",
    "\n",
    "The empirical result that seasons long past should be discounted or discarded suggests that there is no time-independent effect, and the fact that a team's composition varies over time suggests we shouldn't expect one.\n",
    "Note, however, that a reversion-to-the-mean effect might still be apparent from season to season. One possible\n",
    "reason for such an effect is the AFL player draft that happens at the end of each season, which is explicitly designed to allow weaker teams to draft stronger players, in order to help even out the competition for the next season.\n",
    "In other words, we might expect the weakest teams in any one season to improve in the next season, at the expense of the 'average' teams.\n",
    "However, the strongest teams would likely try to retain their best players, and might not be as affected by the draft, although they perhaps could afford to release some older players and take on some younger players, which might affect performance. In other words, it is unclear why truly strongs teams might perform slightly worse the next season, especially if individual teams do not have an underlying mean performance over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a41b6a",
   "metadata": {},
   "source": [
    "### Data scarcity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97feade5",
   "metadata": {},
   "source": [
    "We now have quite a bit of AFL data for years 1997 to the present (or nearly to the present, depending upon how often we update the match data). However, when we start delving into the data at the level of team A versus team B, we begin to run into the problem of data scarcity. This problem is exacerbated when we try to model rare events. For example, drawn matches definitely do occur, but not very often. Thus, given all historical matches between two particular teams A and B, we might never have observed a draw, but we must not rule out the possibility of a draw in the future.\n",
    "\n",
    "The problem of data scarcity becomes even worse if we attempt to model effects that vary over time. Consequently, \n",
    "it is more\n",
    "tractable to ignore time-varying effects, such as changes in composition and ability of teams, and to assume that all model parameters remain constant over time, i.e. are temporally homogeneous. Note that this does not prevent us from modelling temporal sequences, but merely asserts that all temporal sequences are generated by the same fixed process with time-invariant dependencies.\n",
    "However, given the warning of the previous \n",
    "[section](#Temporal-heterogeneity \"Section: Temporal heterogeneity\") \n",
    "about the doubtful existence of time-invariant properties, it would probably be prudent to restrict explicit temporal modelling to just the current\n",
    "season under consideration, rather than seeking a \n",
    "solution over the long-term.\n",
    "\n",
    "Further note that since there are more historical matches (in any given season) near the end of the season compared to the start of the season, our early predictions will typically need to be tempered with prior estimates to offset intra-seasonal data scarcity.\n",
    "It is (potentially) reasonable to use data from the previous season to form these prior estimates.\n",
    "However, empirically it is found that we should restrict our models to using prior probabilities \n",
    "(see the [section](#Backoff-and-smoothing \"Section: Backoff and smoothing\") on smoothing) rather than prior counts, since using prior counts will swamp the current counts observed early in the season.\n",
    "In particular, using prior counts exacerbates an effect noted in the previous \n",
    "[section](#Temporal-heterogeneity \"Section: Temporal heterogeneity\"), namely that teams may have good seasons and bad seasons. Hence, a good season followed by an average or bad season will give overly-optimistic priors,\n",
    "and a bad season followed by an average or good season will give overly-pesimistic priors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad8045",
   "metadata": {},
   "source": [
    "### Model validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a39466",
   "metadata": {},
   "source": [
    "In order to fairly test our ideas, we should partition the observed data into *training* data, that can be used to estimate the parameters of our various models, and *testing* data, on which we can test the accuracies of the models' predictions. These two data sets must be independent of each other.\n",
    "\n",
    "The partitioning of temporal data is not straightforward. Ideally, we would like to segment the data into contiguous blocks, and assign some blocks to the training set and some to the testing set, preferably at random. Mitigating against this strategy is the problem of meaningfully extracting historical quantities of interest, particularly if these quantities are based on temporal relationships.\n",
    "\n",
    "To put it more concretely, suppose we built a system that took in data from year $X$ to year $Y$, and used it to predict the outcomes of matches in year $Y+1$. That is, we segregated the data between years $X$ to $Y$ and year $Y+1$ into the training and testing sets, respectively.\n",
    "Now, once the football season is over for year $Y+1$, may we add that year's data to the system, in order to better predict year $Y+2$? If we pursue this course, then we have the problem that testing data ultimately become training data.\n",
    "\n",
    "Alternatively, suppose we wanted to predict the outcomes of the finals rounds using known outcomes the minor rounds, for each season. Then we might simply assign some entire seasons to the training data and some to the testing data. However, if season $Y+1$ ends up in the training set, and season $Y$ ends up in the testing set, then are we allowed to use the temporal sequence $Y\\rightarrow Y+1$ in our modelling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b766a73d",
   "metadata": {},
   "source": [
    "To answer these questions, we return to our \n",
    "[earlier](#Causality-and-independence-of-observations \"Section: Causality and independence of observations\") \n",
    "assumption of temporal independence of observations.\n",
    "We showed that if we extract all historical match features, i.e. \n",
    "$\\mathbf{X}=[\\mathbf{x}^{(1)},\\mathbf{x}^{(2)},\\ldots]$,\n",
    "then each case $(c^{(t)},\\mathbf{x}^{(t)})$, i.e. match outcome and match features at time $t$, is indepdendent\n",
    "of the other cases. Consequently, the individual cases may be arbitrarily partitioned into training and testing sets.\n",
    "\n",
    "Conceptually, it no longer matters whether we compute the features in advance of\n",
    "partitioning the data, or instead partition the data first and then compute the features\n",
    "on the fly. We are permitted to use cases in the *testing* data as historical context\n",
    "for computing features of the *training* data, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bf0f73",
   "metadata": {},
   "source": [
    "## Basics of Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ba021",
   "metadata": {},
   "source": [
    "Here we discuss some of the common assumptions and interpretations\n",
    "of our various predictive models with respect to the historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc8c6c",
   "metadata": {},
   "source": [
    "### Probabilistic classification and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e4b7ab",
   "metadata": {},
   "source": [
    "Each match has a result or outcome in the\n",
    "set $\\mathcal{C}=\\{\\mathtt{win},\\mathtt{draw},\\mathtt{loss}\\}$\n",
    "of outcomes (or classes). Thus, we take each model to be in the form\n",
    "of a *probabilistic classifier*, giving a probability estimate for\n",
    "each outcome in $\\mathcal{C}$. For convenience, these probabilities\n",
    "will always be represented in the order $\\mathbf{p}\\doteq[p_\\mathtt{win},p_\\mathtt{draw},p_\\mathtt{loss}]$.\n",
    "Note that since a win for one team is a loss for the opposing team, we \n",
    "(arbitrarily but consistently) interpret each match prediction and outcome with respect to\n",
    "the 'for' team versus the 'against' team.\n",
    "\n",
    "The accuracy of a probabilistic model can be measured by how\n",
    "well the estimated probabilites of each match outcome agree with the known outcomes.\n",
    "Thus, for a given match, we let $\\hat{\\mathbf{p}}$ denote the estimated probabilities of outcomes \n",
    "$\\mathcal{C}$, and let $\\bar{\\mathbf{p}}$ denote the true probabilities,\n",
    "i.e. $\\bar{p}_c=\\delta(c=c^{(t)})$ for known outcome $c^{(t)}$,\n",
    "where $\\delta(X)=1$ (or $0$) if Boolean proposition $X$ is true\n",
    "(or false, respectively).\n",
    "\n",
    "Some typical measures of predictive accuracy (or inaccuracy) thus include:\n",
    "\\begin{eqnarray}\n",
    "\\textbf{absolute error}: &\\;\\;& \\|\\hat{\\mathbf{p}}-\\bar{\\mathbf{p}}\\|_1=\\sum_{c\\in\\mathcal{C}}|\\hat{p}_c-\\bar{p}_c|\\,;\n",
    "\\\\\n",
    "\\textbf{square error}: &\\;\\;& \\|\\hat{\\mathbf{p}}-\\bar{\\mathbf{p}}\\|_2^2\n",
    "=\\sum_{c\\in\\mathcal{C}}(\\hat{p}_c-\\bar{p}_c)^2\\,;\n",
    "\\\\\n",
    "\\textbf{zero-one accuracy}: &\\;\\;& \\sum_{c\\in\\mathcal{C}}\\bar{p}_c\n",
    "\\delta(\\hat{p}_c=\\mathtt{max}(\\hat{\\mathbf{p}}))\\,;\n",
    "\\\\\n",
    "\\textbf{cross-entropy}: &\\;\\;& \\sum_{c\\in\\mathcal{C}}\\bar{p}_c\\log\\hat{p}_c\\,.\n",
    "\\end{eqnarray}\n",
    "These are essentially all *posterior* measures since they rely on the computation\n",
    "of $\\hat{p}_c\\doteq P(c\\mid\\mathbf{x},\\hat{\\boldsymbol{\\theta}})$, where $\\mathbf{x}$ denotes the \n",
    "[features](#Feature-Extraction \"Section: Feature Extraction\") extracted from all available information about a given match, and $\\hat{\\boldsymbol{\\theta}}$ denotes an estimate of the model parameters.\n",
    "\n",
    "Another approach is the *maximum likelihood* method\n",
    "(see [Appendix C](C_regression_models.ipynb#Maximum-likelihood-estimation\n",
    "\"Section: Maximum likelihood estimation\")),\n",
    "where we seek $\\hat{\\boldsymbol{\\theta}}=\\boldsymbol{\\theta}_\\texttt{ML}$ to maximise the sample mean of\n",
    "$\\log p(\\mathbf{x}\\mid c,\\boldsymbol{\\theta})$, which subsequently provides another measure of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28bf533",
   "metadata": {},
   "source": [
    "### Indifference to team ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69247616",
   "metadata": {},
   "source": [
    "Next,\n",
    "we note that each match specifies a 'for' team (say, team A) and an 'against' team (say, team B). These labels are purely arbitrary, and are independent of other match characteristics, such as\n",
    "which team is to play at home and which to play away. For simplicity,\n",
    "each model will always predict the match outcome with respect to the 'for' team. Consequently, a label of $\\mathtt{win}$ represents\n",
    "a win for the 'for' team and a loss for the 'against' team, and\n",
    "conversely a label of $\\mathtt{loss}$ represents a loss for the 'for' team and a win for the 'against' team.\n",
    "Where it becomes necessary to distinguish the results by team, we shall append a team subscript to the outcome, such that\n",
    "$\\mathtt{win}_A=\\mathtt{loss}_B$, $\\mathtt{loss}_A=\\mathtt{win}_B$\n",
    "and $\\mathtt{draw}_A=\\mathtt{draw}_B$.\n",
    "\n",
    "Due to the fact that the 'for' and 'against' labels are arbitrary,\n",
    "each predictive model must be indifferent to the order of the match teams, in the following sense. \n",
    "Suppose for a given match we have extracted the combined features $\\mathbf{x}$\n",
    "for both team A and team B, which includes any other \n",
    "[environmental factors](#Environmental-features \"Section: Environmental features\") for the match.\n",
    "Now let a predictive model $\\mathcal{M}$ be defined such that\n",
    "$\\hat{\\mathbf{p}}_\\mathcal{M}$ specifies the vector of probabilities of a win, draw or loss, namely\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\mathcal{M}(A,B) & ~\\doteq~ & \n",
    "[\n",
    "P(\\mathtt{win}_A\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M}),\n",
    "P(\\mathtt{draw}_A\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M}),\n",
    "P(\\mathtt{loss}_A\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "]\n",
    "\\\\&~=~&\n",
    "[\n",
    "P(\\mathtt{loss}_B\\mid \\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M}),\n",
    "P(\\mathtt{draw}_B\\mid \\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M}),\n",
    "P(\\mathtt{win}_B\\mid \\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "]\\,.\n",
    "\\end{eqnarray}\n",
    "By convention, we take the first specified team, here team A, to be the 'for' team, and the second\n",
    "specified team, here team B, to be the 'against' team.\n",
    "It then follows that we must conversely have\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\mathcal{M}(B,A) & ~\\doteq~ & \n",
    "[\n",
    "P(\\mathtt{win}_B\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M}),\n",
    "P(\\mathtt{draw}_B\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M}),\n",
    "P(\\mathtt{loss}_B\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "]\n",
    "\\\\&~=~&\n",
    "[\n",
    "P(\\mathtt{loss}_A\\mid \\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M}),\n",
    "P(\\mathtt{draw}_A\\mid \\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M}),\n",
    "P(\\mathtt{win}_A\\mid \\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "]\\,.\n",
    "\\end{eqnarray}\n",
    "More concisely, if some deterministic function $w$ estimates the\n",
    "probability of a win, such that\n",
    "\\begin{eqnarray}\n",
    "w_\\mathcal{M}(A,B) & ~\\doteq~ & \n",
    "P(\\mathtt{win}_A\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M}) ~=~ \n",
    "P(\\mathtt{loss}_B\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M})\\,,\n",
    "\\end{eqnarray}\n",
    "and some function $d$ estimates the probability of a draw, such that\n",
    "\\begin{eqnarray}\n",
    "d_\\mathcal{M}(A,B) & ~\\doteq~ & \n",
    "P(\\mathtt{draw}_A\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M})~=~ \n",
    "P(\\mathtt{draw}_B\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M})\\,,\n",
    "\\end{eqnarray}\n",
    "then $d_\\mathcal{M}(B,A)=d_\\mathcal{M}(A,B)$ and\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\mathcal{M}(A,B) & = & [w_\\mathcal{M}(A,B),\\;d_\\mathcal{M}(A,B),\\;w_\\mathcal{M}(B,A)]\\,.\n",
    "\\end{eqnarray}\n",
    "The individual probability estimates must, of course, satisfy the invariant\n",
    "\\begin{eqnarray}\n",
    "w_\\mathcal{M}(A,B)+d_\\mathcal{M}(A,B)+w_\\mathcal{M}(B,A) &~=~& 1\\,.\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3756972",
   "metadata": {},
   "source": [
    "### Marginal models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314b72b9",
   "metadata": {},
   "source": [
    "In the [previous](#Indifference-to-team-ordering \"Section:# Indifference to team ordering\") section,\n",
    "we examined some properties of a predictive model $\\mathcal{M}$ that relied on information $\\mathbf{x}$ about\n",
    "both teams A and B. Such a model might be termed a *two-team* model.\n",
    "In contrast, in certain situations (see the [next](#Logistic-models \"Section: Logistic models\") section) it might be reasonable to consider a simplified model\n",
    "that estimates the respective probabilities of a win, draw or loss for team A against *any* arbitrary opponent.\n",
    "This gives rise to a *marginal* model, or a so-called *one-team* model, specified by\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\mathcal{M}(A,*) & ~\\doteq~ & \n",
    "[\n",
    "P(\\mathtt{win}_A\\mid\\mathbf{x}_{A*},\\boldsymbol{\\theta}_\\mathcal{M}),\n",
    "P(\\mathtt{draw}_A\\mid\\mathbf{x}_{A*},\\boldsymbol{\\theta}_\\mathcal{M}),\n",
    "P(\\mathtt{loss}_A\\mid\\mathbf{x}_{A*},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "]\\,,\n",
    "\\end{eqnarray}\n",
    "where now $\\mathbf{x}_{A*}$ represents the features of $\\mathbf{x}$ specific for team A, including environmental factors,\n",
    "essentially with the corresponding features for team B replaced by 'average' values.\n",
    "\n",
    "Conversely, we might consider the respective probabilities of a win, draw or loss\n",
    "for any arbitrary opponent *against* team B. In this case,\n",
    "the probabilities **from the perspective of team A** are given by\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\mathcal{M}(*,B) & ~\\doteq~ & \n",
    "[\n",
    "P(\\mathtt{loss}_B\\mid\\mathbf{x}_{*B},\\boldsymbol{\\theta}_\\mathcal{M}),\n",
    "P(\\mathtt{draw}_B\\mid\\mathbf{x}_{*B},\\boldsymbol{\\theta}_\\mathcal{M}),\n",
    "P(\\mathtt{win}_B\\mid\\mathbf{x}_{*B},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "]\\,,\n",
    "\\end{eqnarray}\n",
    "where $\\mathbf{x}_{*B}$ now represents the features specific for team B against an 'average' opponent.\n",
    "Clearly, in the case where we replace both teams A and B by 'average' teams, we obtain the prior\n",
    "probabilities\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\texttt{prior} & ~\\doteq~ &\n",
    "\\hat{\\mathbf{p}}_\\mathcal{M}(*,*)~=~\n",
    "[P(\\texttt{win}),P(\\texttt{draw}),P(\\texttt{loss})]\\,,\n",
    "\\end{eqnarray}\n",
    "where $P(\\mathtt{win})=P(\\mathtt{loss})=\\frac{1}{2}[1-P(\\mathtt{draw})]$, since there are no *a priori* reasons to choose team A over team B.\n",
    "\n",
    "An [additive](#Combined-models \"Section: Combined models\") two-team model $\\mathcal{M}_\\texttt{add}$ that obeys our restriction of \n",
    "[indifference to team ordering](#Indifference-to-team-ordering \"Section:# Indifference to team ordering\")\n",
    "is then given by\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\mathtt{add}(A,B) & ~\\doteq~ &\n",
    "\\lambda\\;\\hat{\\mathbf{p}}_\\texttt{prior}\n",
    "+\\frac{1-\\lambda}{2}\\;\\hat{\\mathbf{p}}_\\mathcal{M}(A,*)\n",
    "+\\frac{1-\\lambda}{2}\\;\\hat{\\mathbf{p}}_\\mathcal{M}(*,B)\\,,\n",
    "\\end{eqnarray}\n",
    "for prior weight $\\lambda\\in[0,1]$.\n",
    "\n",
    "Alternatively, a [multiplicative](#Combined-models \"Section: Combined models\") two-team model $\\mathcal{M}_\\texttt{mult}$ is given by\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\mathtt{mult}(A,B) & ~\\doteq~ & \n",
    "\\hat{\\mathbf{p}}_\\mathcal{M}(A,*)\\otimes\\hat{\\mathbf{p}}_\\mathcal{M}(*,B)\\oslash\\hat{\\mathbf{p}}_\\mathcal{M}(*,*)\n",
    "~\\doteq~\\texttt{renorm}([w,d,\\ell])\\,,\n",
    "\\end{eqnarray}\n",
    "with\n",
    "\\begin{eqnarray}\n",
    "w & = & \\frac{P(\\mathtt{win}_A\\mid\\mathbf{x}_{A*},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "      \\,P(\\mathtt{loss}_B\\mid\\mathbf{x}_{*B},\\boldsymbol{\\theta}_\\mathcal{M})}\n",
    "     {P(\\mathtt{win})}\\,,\n",
    "\\\\\n",
    "d & = & \\frac{P(\\mathtt{draw}_A\\mid\\mathbf{x}_{A*},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "      \\,P(\\mathtt{draw}_B\\mid\\mathbf{x}_{*B},\\boldsymbol{\\theta}_\\mathcal{M})}\n",
    "     {P(\\mathtt{draw})}\\,,\n",
    "\\\\\n",
    "\\ell & = & \\frac{P(\\mathtt{loss}_A\\mid\\mathbf{x}_{A*},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "      \\,P(\\mathtt{win}_B\\mid\\mathbf{x}_{*B},\\boldsymbol{\\theta}_\\mathcal{M})}\n",
    "     {P(\\mathtt{loss})}\\,.\n",
    "\\end{eqnarray}\n",
    "Note that for convenience we have defined the operator $\\otimes$ to represent element-wise vector multiplication with renormalisation,\n",
    "and let $\\oslash$ denote element-wise vector division with renormalisation, such that the renormalisation\n",
    "of an arbitrary vector $\\mathbf{v}=[v_1,v_2,\\ldots,v_n]$ is given by\n",
    "\\begin{eqnarray}\n",
    "\\texttt{renorm}(\\mathbf{v}) & ~\\doteq~ & \\frac{\\mathbf{v}}{\\|\\mathbf{v}\\|_1}\\,,\n",
    "\\end{eqnarray}\n",
    "where $\\|\\mathbf{v}\\|_1\\doteq\\sum_{i=1}^n|v_i|$. In practice, renormalisation may be delayed until after\n",
    "all vector operations have been performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd6401",
   "metadata": {},
   "source": [
    "### Logistic models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082f3650",
   "metadata": {},
   "source": [
    "A useful model for predicting probabilities is provided by *logistic regression*, particularly\n",
    "[Bernoulli regression](#C_regression_models.ipynb#Bernoulli-regression \"Appendix C: Regression models\").\n",
    "Such a model enables us to make direct use of the [features](#Feature-Extraction \"Section: Feature Extraction\") $\\mathbf{x}$ for opposing teams, say teams A and B, in order to predict the outcome of an upcoming match.\n",
    "\n",
    "In general, we might use a multi-class logistic classifier, which predicts the probabilities of a win, a draw, or a loss. However, as noted [earlier](#The-effect-of-draws \"Section: The effect of draws\"), draws are relatively rare events that are difficult to predict. Hence, for most of our modelling we shall simply assume some fixed, prior probability $p_\\texttt{draw}$ of a draw, such that\n",
    "\\begin{eqnarray}\n",
    "d_\\mathcal{M}(A,B) & ~=~ &\n",
    "P(\\texttt{draw}_A\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M}) ~\\doteq~ p_\\texttt{draw}\\,.\n",
    "\\end{eqnarray}\n",
    "This now allows us to simplify the model to a two-class classifier of the form\n",
    "\\begin{eqnarray}\n",
    "w_\\mathcal{M}(A,B) & ~=~ & P(\\texttt{win}_A\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "~\\doteq~ (1-p_\\texttt{draw})\\,\\rho(\\mathbf{x};\\boldsymbol{\\theta}_\\mathcal{M})\\,,\n",
    "\\end{eqnarray}\n",
    "where, in order to satisfy the \n",
    "[invariance](#Indifference-to-team-ordering \"Section: Indifference to team ordering\") constraint,\n",
    "we must also have\n",
    "\\begin{eqnarray}\n",
    "w_\\mathcal{M}(B,A) & ~=~ & P(\\texttt{win}_B\\mid\\mathbf{x},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "~\\doteq~ (1-p_\\texttt{draw})\\,[1-\\rho(\\mathbf{x};\\boldsymbol{\\theta}_\\mathcal{M})]\\,.\n",
    "\\end{eqnarray}\n",
    "The function $\\rho$ now represents any arbitrary regression function that maps its arguments into $[0,1]$\n",
    "or $(0,1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b6ecc0",
   "metadata": {},
   "source": [
    "Note that so far we have glossed over the structure of the features $\\mathbf{x}$. However, we have implicitly assumed that, for any given model $\\mathcal{M}$, the same features will be extracted for opposing teams A and B for a given match,\n",
    "regardless of team order. \n",
    "In order to achieve this indifference to team ordering, we now suppose that we\n",
    "may partition the features as $\\mathbf{x}=\\mathbf{z}_A\\oplus\\mathbf{z}_B$, where $\\mathbf{z}_A$ specifies\n",
    "features in favour of team A winning, and $\\mathbf{z}_B$ specifies features in favour of team B.\n",
    "Neglecting draws, we therefore see that \n",
    "$\\rho(\\mathbf{x};\\boldsymbol{\\theta}_\\mathcal{M})=\\rho(\\mathbf{z}_A,\\mathbf{z}_B;\\boldsymbol{\\theta}_\\mathcal{M})$\n",
    "gives the probability of team A winning against team B. Thus, swapping the order of team A and B, we deduce\n",
    "that $\\rho(\\mathbf{z}_B,\\mathbf{z}_A;\\boldsymbol{\\theta}_\\mathcal{M})$\n",
    "gives the probability of team B winning against team A. But this is just \n",
    "$1-\\rho(\\mathbf{z}_A,\\mathbf{z}_B;\\boldsymbol{\\theta}_\\mathcal{M})$ from above for a two-class classifier, so\n",
    "the function $\\rho$ must satisify\n",
    "\\begin{eqnarray}\n",
    "\\rho(\\mathbf{z}_A,\\mathbf{z}_B;\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "+\\rho(\\mathbf{z}_B,\\mathbf{z}_A;\\boldsymbol{\\theta}_\\mathcal{M}) & ~=~ & 1\\,,\n",
    "\\end{eqnarray}\n",
    "for any features $\\mathbf{z}_A$ and $\\mathbf{z}_B$ in general.\n",
    "The simplest function with this property is provided by the linear logistic regression model, namely\n",
    "\\begin{eqnarray}\n",
    "P(\\texttt{win}_A\\mid\\mathbf{z}_A,\\mathbf{z}_B,\\overline{\\texttt{draw}},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "& ~=~ & \\rho(\\mathbf{z}_A,\\mathbf{z}_B;\\boldsymbol{\\theta}_\\mathcal{M}) ~\\doteq~\n",
    "\\sigma(\\mathbf{w}\\cdot(\\mathbf{z}_A-\\mathbf{z}_B))\\,,\n",
    "\\end{eqnarray}\n",
    "where $\\sigma:\\mathbb{R}\\mapsto(0,1)$ denotes the\n",
    "*logistic* transformation $\\sigma(x)\\doteq(1+e^{-x})^{-1}$ having the property that\n",
    "$\\sigma(-x)=1-\\sigma(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6096c1e",
   "metadata": {},
   "source": [
    "We [previously](#Marginal-models \"Section: Marginal models\") alluded to the fact that the above *two-team* model\n",
    "may in some circumstances be reduced to a simplified *one-team* model.\n",
    "We are now in a position to consider what form this one-team model might take.\n",
    "The use of a one-team model might be justified, for example, by utilising some\n",
    "theoretical relationship between paired features, say $\\mathbf{z}_B=\\mathbf{f}(\\mathbf{z}_A)$.\n",
    "This is the case, for instance, when considering that if one team is playing at its \n",
    "home ground then the opposing team must be playing away from its home ground \n",
    "(see [Chapter 5](5_match_effects.ipynb#Home-ground-advantage \"Match Effects: Home-ground advantage\")).\n",
    "\n",
    "Alternatively, we might wish to test the predictive ability of the features $\\mathbf{z}_A$ for team A\n",
    "in isolation to team B by considering an 'average' opponent, which corresponds to\n",
    "replacing $\\mathbf{z}_B$ by either its expected value, $\\mathbb{E}[x_B]$, \n",
    "or its empirical mean, $\\langle x_B\\rangle$.\n",
    "\n",
    "Consequently, the two-team model for team A against team B might be replaced by a one-team model for team A,\n",
    "which then takes the form\n",
    "\\begin{eqnarray}\n",
    "P(\\texttt{win}_A\\mid\\mathbf{z}_A,\\overline{\\texttt{draw}},\\boldsymbol{\\theta}_\\mathcal{M})\n",
    "& ~=~ & \\rho(\\mathbf{z}_A,*;\\boldsymbol{\\theta}_\\mathcal{M}) ~\\doteq~\n",
    "\\sigma(w_0+\\mathbf{w}\\cdot\\mathbf{z}_A))\\,,\n",
    "\\end{eqnarray}\n",
    "where we have notionally replaced features $\\mathbf{z}_B$ by some arbitrary but constant values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06bfad8",
   "metadata": {},
   "source": [
    "### Combined models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8245a087",
   "metadata": {},
   "source": [
    "Another useful modelling technique is to combine a collection \n",
    "$(\\mathcal{M}_1,\\mathcal{M}_2,\\ldots,\\mathcal{M}_M)$ of sub-models, where each sub-model typically utilises a different subset of the match features. We briefly examined such *ensemble* modelling\n",
    "[earlier](#Marginal-models \"Section: Marginal models\") when combining marginal models derived\n",
    "from the perspective of each opposing team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46548b46",
   "metadata": {},
   "source": [
    "In general, a weighted additive combination $\\mathcal{M}_\\texttt{add}$ of these sub-models takes the form\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\mathtt{add}(A,B) & \\doteq &\n",
    "\\sum_{k=1}^{M}w_k\\,\\hat{\\mathbf{p}}_{\\mathcal{M}_k}(A,B)\\,,\n",
    "\\end{eqnarray}\n",
    "where $w_k\\ge 0$ and $\\sum_{k=1}^{M}w_k=1$.\n",
    "The sub-model weights may either be chosen in advance, or estimated from the training data via iterative posterior updates (see [Appendix A](A_additive_weights.ipynb \"Appendix A: Additively Weighted Models\")), namely\n",
    "\\begin{eqnarray}\n",
    "w_k & \\leftarrow & \\frac{1}{N}\\sum_{d=1}^{N}\n",
    "\\frac{w_{k}\\,\\hat{\\mathbf{p}}_{\\mathcal{M}_k}(A^{(d)},B^{(d)})[c^{(d)}]}\n",
    "{\\hat{\\mathbf{p}}_\\mathtt{add}(A^{(d)},B^{(d)})[c^{(d)}]}\n",
    "\\,,\n",
    "\\end{eqnarray}\n",
    "where\n",
    "$A^{(d)}$ and $B^{(d)}$ denote the 'for' and 'against' teams, respectively, for the $d$-th match, \n",
    "and $\\hat{\\mathbf{p}}[c^{(d)}]$ returns the predicted probability of the true outcome $c^{(d)}$ of the match."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af00f6e",
   "metadata": {},
   "source": [
    "The multiplicative combination of sub-models has some stricter conditions, namely that the feature sets for each sub-model are non-overlapping and uncorrelated. Under these conditions, the (unweighted) multiplicative model \n",
    "$\\mathcal{M}_\\texttt{mult}$ is now given by\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\mathtt{mult}(A,B) & \\doteq & \n",
    "\\hat{\\mathbf{p}}_\\mathtt{prior}(A,B)\\,\\otimes_{k=1}^{M}\\,\n",
    "\\left[\\hat{\\mathbf{p}}_{\\mathcal{M}_k}(A,B)\\oslash\\hat{\\mathbf{p}}_\\mathtt{prior}(A,B)\\right]\\,.\n",
    "\\end{eqnarray}\n",
    "\n",
    "This combined model is only approximate if sub-models share common features, or if features are correlated across different sub-models. In order to help reduce the effects of dependence or correlation, we could instead use the weighted form\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\mathtt{mult}(A,B) & \\doteq & \n",
    "\\hat{\\mathbf{p}}_\\mathtt{prior}(A,B)\\,\\otimes_{k=1}^{M}\\,\n",
    "\\left[\\hat{\\mathbf{p}}_{\\mathcal{M}_k}(A,B)\\oslash\\hat{\\mathbf{p}}_\\mathtt{prior}(A,B)\\right]^{w_k}\\,.\n",
    "\\end{eqnarray}\n",
    "However, unlike for the additive model, there are no obvious constraints on the weights.\n",
    "Instead, upon taking logarithms, it follows that the weighted multiplicative model is equivalent to an additive logistic classifier with features of the form\n",
    "$\\mathbf{z}=\\left[\\log\\left\\{\\hat{\\mathbf{p}}_{\\mathcal{M}_k}(A,B)\\oslash\\hat{\\mathbf{p}}_\\mathtt{prior}(A,B)\n",
    "\\right\\}\\right]_{k=1}^{M}$. Thus, we may instead train a logistic classifier using arbitrary weight regularisation, e.g. $L_2$ and/or $L_1$ norms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c828b34",
   "metadata": {},
   "source": [
    "### Backoff and smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b373a998",
   "metadata": {},
   "source": [
    "When attempting to predict the outcome of a match between two teams, say team A and team B, it might be useful to consider any previous matches played by team A against team B within some pre-determined time period.\n",
    "For example, suppose we count the previous games played by team A against B within the current season, and wish to compute the model\n",
    "$\\mathcal{M}_\\texttt{count}$ given by\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\texttt{count}(A,B) & ~\\doteq~ &\n",
    "\\texttt{renorm}\\left([c(\\mathtt{win}_{A,B}),c(\\mathtt{draw}_{A,B}),c(\\mathtt{loss}_{A,B})]\\right)\\,,\n",
    "\\end{eqnarray}\n",
    "where $c(X_{A,B})$ counts the number of matches played between teams A and B with a result of $X$ for team A.\n",
    "\n",
    "What do we do if all of the counts are zero, i.e. team A has not previously played\n",
    "against team B (at least within the historical context under consideration)?\n",
    "For example, suppose that team B is playing their debut season, and they have not yet played against team A.\n",
    "One solution is to *back-off* from unobserved quantities (e.g. counting matches played by both teams together) to observed quantities (e.g. counting matches played by each team separately).\n",
    "Thus, we could consider the matches that teams A and B have separately played against other opponents, giving rise to\n",
    "[marginal models](#Marginal-models \"Section: Marginal models\") of the form\n",
    "$\\hat{\\mathbf{p}}_\\texttt{count}(A,*)$ and $\\hat{\\mathbf{p}}_\\texttt{count}(*,B)$, and a combined\n",
    "model $\\mathcal{M}_\\texttt{backoff}$ given by\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\mathtt{backoff}(A,B) & ~\\doteq~ &\n",
    "\\frac{1}{2}\\hat{\\mathbf{p}}_\\texttt{count}(A,*)+\\frac{1}{2}\\hat{\\mathbf{p}}_\\texttt{count}(*,B)\n",
    "\\,.\n",
    "\\end{eqnarray}\n",
    "Note that here we take $c(X_{A,*})$ to be the number of matches played by team A against any opponent with\n",
    "an outcome of $X$ for team A. Similarly, $c(X_{*,B})$ is the number of matches played by team B against any opponent with an outcome of $X$ for team B's opponent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccea4ab",
   "metadata": {},
   "source": [
    "However, now what if team B has (within the historical context) not played *any* matches?\n",
    "For example, suppose that it is the first round in team B's debut season?\n",
    "In this case, we could back-off further from $\\hat{\\mathbf{p}}_\\texttt{count}(*,B)$ to the prior model\n",
    "$\\hat{\\mathbf{p}}_\\texttt{prior}(*,*)=[p_\\mathtt{win},p_\\mathtt{draw},p_\\mathtt{loss}]$.\n",
    "\n",
    "Alternatively, what if it is early in the season and team B has played a few matches, but the observed counts are too small to provide reliable estimates of future performance?\n",
    "For example, suppose team B has not yet drawn a match (which is quite likely, since draws are comparatively rare\n",
    "events).\n",
    "In this case, we might take the smoothed model $\\mathcal{M}_\\texttt{smooth}$ to be\n",
    "\\begin{eqnarray}\n",
    "\\hat{\\mathbf{p}}_\\mathtt{smooth}(*,B) & ~\\doteq~ &\n",
    "\\texttt{renorm}\\left(\\lambda\\;\\hat{\\mathbf{p}}_\\texttt{prior}+\n",
    "[c(\\mathtt{win}_{*,B}),c(\\mathtt{draw}_{*,B}),c(\\mathtt{loss}_{*,B})]\n",
    "\\right)\n",
    "\\,,\n",
    "\\end{eqnarray}\n",
    "where $\\lambda>0$ represents the number of prior pseudo-matches 'played' by team B.\n",
    "Note that in this case, if all of the counts are zero then the smoothed model reduces\n",
    "to the prior (backoff) model. Hence, in general, a (variable) combination of back-off and smoothing may be applied to each model, depending upon circumstances. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1ac404",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697ba81",
   "metadata": {},
   "source": [
    "Earlier, we discussed the problem of \n",
    "[data scarcity](#Data-scarcity \"Section: Data scarcity\") \n",
    "and the need for \n",
    "[marginal models](#Marginal-models \"Section: Marginal models\") \n",
    "that predict the outcomes of matches between a specified team and any other, arbitrary team.\n",
    "Useful types of information for such models include *environmental* features and *historical* features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b6b02",
   "metadata": {},
   "source": [
    "### Environmental features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54fb88f",
   "metadata": {},
   "source": [
    "Environmental features indicate expected information about the match conditions, such as \n",
    "weather (e.g. cloudy or sunny, windy or calm, rainy or dry),\n",
    "light conditions (e.g. day or night match), and ground conditions (e.g. physical dimensions, soft or hard turf), et cetera.\n",
    "\n",
    "These features affect team performance during the match. For instance, empirical observations suggest that some teams seem to be able to play better in the rain than other teams, giving them an advantage. However, it not clear how strong these effects might be, and further analysis is required. Additionally, weather prediction is uncertain, and some degree of model sophistication would be required to allow for this\n",
    "uncertainty. Typically, it is easier to use simple models and ignore the environmental effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227af19b",
   "metadata": {},
   "source": [
    "One strong environmental feature, however, is the so-called *home-ground advantage*.\n",
    "It has been noted in the literature for many different sporting games that there is a distinct effect whereby the team playing on their home ground (the 'home' team) has \n",
    "an advantage against the opposing side (the 'away' team, who must travel to the match ground). It is still unclear as to whether this advantage is physical or psychological. \n",
    "\n",
    "Physical effects might include better familiarity of the 'home' team with the peculiarities of their oval (e.g. dimensions, surface hardness, boggy patches, etc.).\n",
    "Alternatively, the 'away' team might suffer from fatigue caused by having to travel (possibly interstate) to another ground.\n",
    "\n",
    "Psychologically, it could simply be a matter of confidence (again, familiarity with\n",
    "the ground), or pride for the 'home' team playing in front of the local fans, and thus\n",
    "a determination not to lose face.\n",
    "\n",
    "Regardless of the cause, AFL matches also demonstrate the home-ground advantage, such that the home team wins about 55% of its matches (averaged across seasons and teams). Consequently, we must allow for this effect in our predictive modelling, and also in the analysis of the accuracy of such models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73569c3",
   "metadata": {},
   "source": [
    "### Historical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4685b3d",
   "metadata": {},
   "source": [
    "Historical features involve information we may usefully extract from past matches.\n",
    "However, we cautioned \n",
    "[earlier](#Temporal-heterogeneity \"Section: Temporal heterogeneity\") \n",
    "that matches long in the past might not be relevant, due largely to the fact that teams change in composition over time. Consequently, we expect  temporal variability of teams' relative strengths in offense and defense. This makes such effects difficult to model, especially due to the problem of \n",
    "[data scarcity](#Data-scarcity \"Section: Data scarcity\").\n",
    "\n",
    "In practice, previous analysis of historical match results (not shown here) suggests that, when predicting the outcome of a given match in a given season, the previous matches within that season are most relevant. Additionally, the results of matches from the preceding season are relevant as prior information for the purposes of model\n",
    "backoff and smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae4779c",
   "metadata": {},
   "source": [
    "Useful historical statistics include match scores, match outcomes, and league rankings.\n",
    "For marginal models, the score statistics count the total number of points scored by a team against all other teams (the 'for' score), and the number of points scored against that team by all other teams (the 'against' score). The 'for' score indirectly measures of the offensive strength of the team, and the 'against' score measures the team's defensive strength (or lack thereof).\n",
    "\n",
    "Similarly, the outcome statistics count the number of wins, draws and losses each team has had against all other opponents. Again, the wins indirectly measure offensive strength, and the losses measure defensive strength. Draws indicate that the two opposing teams were about equaly matched on the day (subject to the effect of free kicks awarded by umpires). However, wins and losses do not indicate how close these matches were, and thus the outcome statistics are less finely-grained than the score\n",
    "statistics.\n",
    "\n",
    "Finally, the most coarse-grained of the statistics are the league rankings. Effectively, a higher ranking (i.e. smaller rank index) indicates a stronger team, and a lower ranking\n",
    "(i.e. larger rank index) indicates a weaker team. Note that the rankings are primarily\n",
    "computed from the match points (4 points for a win, and 2 points for a loss).\n",
    "Ties in the number of match points are settled by awarding the higher ranking to the\n",
    "team with the higher score *percentage* (which, for the AFL, is 100% times the\n",
    "number of score points 'for' a team divided by the number of points 'against').\n",
    "Thus, the rankings incorporate both score and outcome statistics.\n",
    "\n",
    "Note that an 'upset' win against a higher ranking opponent should perhaps be given more weight than an 'expected' win against a lower ranking opponent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a394e75e",
   "metadata": {},
   "source": [
    "### Graph features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f480ecd3",
   "metadata": {},
   "source": [
    "A special case of the historical features arises because each match may be considered as an edge between the two opposing teams, with all the teams forming vertices in a graph.\n",
    "The outcome of a match determines the direction of the edge, where a draw is either undirected or bidirectional, depending upon what analytics are to be extracted.\n",
    "\n",
    "Thus, for a *directed* gaph, we may compute both *centrality* and *prestige* features for each team.\n",
    "Essentially, centrality measures the effect of out-edges from a vertex, whereas\n",
    "prestige measures the effect of in-edges. Consequently, the normalised eigenvector scores, and the related PageRank scores, actually measure prestige rather than centrality. For an undirected graph, the prestige scores are exacly equal to the centrality scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a41872",
   "metadata": {},
   "source": [
    "The weight of each edge in a match graph is typically obtained from one of the types of historical statistics. Furthermore, multiple edges between the same two teams (in the same direction) may be amalgamated into a single edge by combining the edge weights,\n",
    "usually by either summing the edge weights, or taking their mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01bb7d0",
   "metadata": {},
   "source": [
    "However, caution should be used in both the application and interpretation of graph (or vertex) statistics. For example, standard PageRank adds implicit teleportation edges between all vertices, but in a sporting context a team may **not** oppose itself.\n",
    "Also, normalised eigenvector scores measure the effect of in-edges but not out-edges, and thus measure the *gain* in prestige of each team, e.g. due to wins, but not the\n",
    "*loss* of prestige, e.g. due to losses (see [Appendix B](B_graph_analytics.ipynb \"Appendix B: Graph Analytics\") for more details)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
