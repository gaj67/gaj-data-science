{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "813c8914",
   "metadata": {},
   "source": [
    "# Appendix D: Predictive Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce153bf",
   "metadata": {},
   "source": [
    "The purpose of this appendix is to discuss some of the predictive distributions arising from various choices of pre-match features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff80392",
   "metadata": {},
   "source": [
    "## Bernoulli distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a464e6",
   "metadata": {},
   "source": [
    "We start by assuming that each match played by some given team, say team A, within a given season has an outcome governed\n",
    "by a Bernoulli distribution with constant but unknown parameter $\\theta$. For simplicity, we shall neglect the usual subscripts that\n",
    "denote the particular team. We now suppose that the team has played $n$ matches, winning $w$ of them and losing \n",
    "$\\ell=n-w$. \n",
    "Note that a draw may be regarded as half-a-win and half-a-loss\n",
    "(see [Appendix C](./C_regression_models.ipynb#Bernoulli-distribution \"Regression Models: Bernoulli distribution\")),\n",
    "such that $w$ and $\\ell$ are adjusted 'counts' (that no longer need be integer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d006e7",
   "metadata": {},
   "source": [
    "### Bernoulli data likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784a1eb9",
   "metadata": {},
   "source": [
    "The joint likelihood of the particular sequence of matches won and lost is therefore\n",
    "\\begin{eqnarray}\n",
    "p(w,n-w\\mid\\theta) & = & \\theta^w\\,(1-\\theta)^{n-w}\\,.\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37488b8d",
   "metadata": {},
   "source": [
    "### Bernoulli prior distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd53eec6",
   "metadata": {},
   "source": [
    "We seek a non-informative prior distribution for $\\theta$. \n",
    "Following Box and Tiao [[1]](#Citations \"Citation [1]: ???\"), \n",
    "we desire a transformation $\\phi(\\theta)$ such that the likelihood plotted as a function of $\\phi$ retains\n",
    "an approximately constant shape for some fixed $n$ as $w$ varies. A uniform prior for $\\phi$ then induces a\n",
    "non-informative prior for $\\theta$. In general, it turns out that the relevant prior is usually inversely\n",
    "proportional to the square-root of the variance. For the Bernoulli distribution, the non-informative\n",
    "prior is therefore\n",
    "\\begin{eqnarray}\n",
    "p(\\theta) ~\\propto~ \\frac{1}{\\sqrt{\\theta\\,(1-\\theta)}}\n",
    "& ~\\Rightarrow~ & \\theta~\\sim~\\mathtt{Beta}\\left(\\frac{1}{2},\\frac{1}{2}\\right)\n",
    "\\,.\n",
    "\\end{eqnarray}\n",
    "This is Jeffreys' prior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e529307b",
   "metadata": {},
   "source": [
    "### Bernoulli posterior distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b568f",
   "metadata": {},
   "source": [
    "Multiplying the likelihood by the prior, we obtain\n",
    "\\begin{eqnarray}\n",
    "p(\\theta,w,n-w) & ~=~ & \\frac{\\theta^{w-\\frac{1}{2}}\\,(1-\\theta)^{n-w-\\frac{1}{2}}}{B(\\frac{1}{2},\\frac{1}{2})}\\,,\n",
    "\\end{eqnarray}\n",
    "where $B(\\alpha,\\beta)$ is the Beta function.\n",
    "Integrating out $\\theta$ then gives\n",
    "\\begin{eqnarray}\n",
    "p(w,n-w) & ~=~ & \\int_0^1 p(\\theta,w,n-w)\\,d\\theta\n",
    "\\\\&~=~&\n",
    "\\int_{0}^{1}\\frac{\\theta^{w-\\frac{1}{2}}\\,(1-\\theta)^{n-w-\\frac{1}{2}}}{B(\\frac{1}{2},\\frac{1}{2})}\\,d\\theta\n",
    "~=~\n",
    "\\frac{B(w+\\frac{1}{2},n-w+\\frac{1}{2})}{B(\\frac{1}{2},\\frac{1}{2})}\\,.\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e4dcb9",
   "metadata": {},
   "source": [
    "The posterior distribution is therefore given by\n",
    "\\begin{eqnarray}\n",
    "p(\\theta\\mid w,n-w) & ~=~ & \\frac{p(\\theta,w,n-w)}{p(w,n-w)}\n",
    "~=~\\frac{\\theta^{w-\\frac{1}{2}}\\,(1-\\theta)^{n-w-\\frac{1}{2}}}\n",
    "{B(w+\\frac{1}{2},n-w+\\frac{1}{2})}\\,,\n",
    "\\\\\n",
    "\\Rightarrow \\theta\\mid w,n-w & ~\\sim~ & \\mathtt{Beta}\\left(w+\\frac{1}{2},n-w+\\frac{1}{2}\\right)\\,.\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f691c541",
   "metadata": {},
   "source": [
    "### Bernoulli predictive distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc66d9b1",
   "metadata": {},
   "source": [
    "Suppose the result of the $(n+1)$-th match is now $X$. Then the likelihood of this result is\n",
    "\\begin{eqnarray}\n",
    "p(X=x\\mid\\theta) & ~=~ & \\theta^{x}\\,(1-\\theta)^{1-x}\\,.\n",
    "\\end{eqnarray}\n",
    "Hence, the predictive probability of this result is given by\n",
    "\\begin{eqnarray}\n",
    "p(X=x\\mid w,n-w) & ~=~ & \\int_0^1 p(x\\mid\\theta)\\,p(\\theta\\mid w,n-w)\\,d\\theta\n",
    "\\\\&~=~&\n",
    "\\int_0^1\\frac{\\theta^{w+x-\\frac{1}{2}}\\,(1-\\theta)^{n-w-x+\\frac{1}{2}}}\n",
    "{B(w+\\frac{1}{2},n-w+\\frac{1}{2})}\\,d\\theta\n",
    "~=~\n",
    "\\frac{B(w+x+\\frac{1}{2},n-w+1-x+\\frac{1}{2})}\n",
    "{B(w+\\frac{1}{2},n-w+\\frac{1}{2})}\n",
    "\\,.\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9d1c4",
   "metadata": {},
   "source": [
    "In terms of the Gamma function, $\\Gamma(\\cdot)$, this becomes\n",
    "\\begin{eqnarray}\n",
    "p(X=x\\mid w,n-w) & ~=~ & \n",
    "\\frac{\\Gamma(w+x+\\frac{1}{2})\\,\\Gamma(n-w+1-x+\\frac{1}{2})}\n",
    "     {\\Gamma(n+x+2)}\\,\n",
    "\\frac{\\Gamma(n+1)}\n",
    "     {\\Gamma(w+\\frac{1}{2})\\,\\Gamma(n-w+\\frac{1}{2})}\\,.\n",
    "\\end{eqnarray}\n",
    "For a loss, i.e. $X=0$, the respective probability reduces to\n",
    "\\begin{eqnarray}\n",
    "p(X=0\\mid w,n-w) & ~=~ & \\frac{n-w+\\frac{1}{2}}{n+1}\\,,\n",
    "\\end{eqnarray}\n",
    "using the recurrence relation that $\\Gamma(z+1)=z\\,\\Gamma(z)$.\n",
    "The corresponding probability of a win is therefore\n",
    "\\begin{eqnarray}\n",
    "p(X=1\\mid w,n-w) & ~=~ & \\frac{w+\\frac{1}{2}}{n+1}\\,,\n",
    "\\end{eqnarray}\n",
    "such that\n",
    "\\begin{eqnarray}\n",
    "p(X=x\\mid w,n-w) & ~=~ & \\frac{(w+\\frac{1}{2})^x\\,(n-w+\\frac{1}{2})^{1-x}}{n+1}\\,.\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abb62c5",
   "metadata": {},
   "source": [
    "Note that the denominator of $n+1$ corresponds to assuming $n$ observed matches plus a single prior pseudo-match.\n",
    "Similarly, the numerator $w+\\frac{1}{2}$ of a win corresponds to $w$ observed wins plus a prior pseudo-draw, \n",
    "i.e. half-a-win.\n",
    "Likewise, the observed $\\ell=n-w$ losses have been *smoothed* by a prior pseudo-draw, i.e. half-a-loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f3cd8",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24764d9b",
   "metadata": {},
   "source": [
    "[1] Box and Tiao???."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
